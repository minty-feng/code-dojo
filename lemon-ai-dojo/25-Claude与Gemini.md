# Claudeä¸Gemini

## ğŸ’¡ æ ¸å¿ƒç»“è®º

1. **Claudeä»¥å®‰å…¨æ€§å’Œé•¿ä¸Šä¸‹æ–‡è‘—ç§°ï¼Œæ”¯æŒ200K tokens**
2. **Claude 3ç³»åˆ—åŒ…æ‹¬Haikuã€Sonnetã€Opusä¸‰ä¸ªç‰ˆæœ¬**
3. **Geminiæ˜¯Googleçš„å¤šæ¨¡æ€å¤§æ¨¡å‹**
4. **Gemini 1.5 Proæ”¯æŒ100ä¸‡tokensè¶…é•¿ä¸Šä¸‹æ–‡**
5. **Claudeå’ŒGeminiåœ¨æŸäº›ä»»åŠ¡ä¸Šè¶…è¶ŠGPT-4**

---

## 1. Claudeç³»åˆ—

### 1.1 ç‰ˆæœ¬æ¼”è¿›

```
2023.03  Claude 1        100Kä¸Šä¸‹æ–‡
2023.07  Claude 2        100Kä¸Šä¸‹æ–‡ï¼Œæ›´å®‰å…¨
2024.03  Claude 3        200Kä¸Šä¸‹æ–‡
  - Haiku:  å¿«é€Ÿè½»é‡
  - Sonnet: å¹³è¡¡æ€§èƒ½
  - Opus:   æœ€å¼ºæ€§èƒ½
2024.06  Claude 3.5 Sonnet  æ€§èƒ½æå‡
```

### 1.2 ä½¿ç”¨Claude API

```python
import anthropic

client = anthropic.Anthropic(api_key="your-api-key")

# åŸºç¡€å¯¹è¯
message = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "è§£é‡Šä¸€ä¸‹Transformeræ¶æ„"}
    ]
)

print(message.content[0].text)

# é•¿æ–‡æ¡£åˆ†æ
with open('long_document.txt', 'r') as f:
    document = f.read()

message = client.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=2000,
    messages=[
        {
            "role": "user",
            "content": f"è¯·æ€»ç»“ä»¥ä¸‹æ–‡æ¡£çš„å…³é”®è¦ç‚¹ï¼š\n\n{document}"
        }
    ]
)

print(message.content[0].text)
```

### 1.3 Claudeç‰¹è‰²åŠŸèƒ½

```python
# ç³»ç»Ÿæç¤º
message = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=1024,
    system="ä½ æ˜¯ä¸€ä¸ªPythonç¼–ç¨‹ä¸“å®¶ï¼Œä»£ç è¦ç®€æ´é«˜æ•ˆ",
    messages=[
        {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åº"}
    ]
)

# æ€ç»´é“¾
message = client.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=2000,
    messages=[
        {
            "role": "user",
            "content": "ä¸€ä¸ªæ°´æ± æœ‰ä¸¤ä¸ªæ°´é¾™å¤´ï¼Œä¸€ä¸ªæ¯å°æ—¶æ³¨æ°´10å‡ï¼Œå¦ä¸€ä¸ªæ¯å°æ—¶æ³¨æ°´15å‡ã€‚åŒæ—¶æœ‰ä¸€ä¸ªæ’æ°´å£æ¯å°æ—¶æ’æ°´8å‡ã€‚ç°åœ¨æ°´æ± æ˜¯ç©ºçš„ï¼Œé—®å¤šä¹…èƒ½è£…æ»¡50å‡æ°´ï¼Ÿè¯·é€æ­¥æ€è€ƒã€‚"
        }
    ]
)
```

---

## 2. Geminiç³»åˆ—

### 2.1 ç‰ˆæœ¬æ¼”è¿›

```
2023.12  Gemini 1.0
  - Nano:  è®¾å¤‡ç«¯
  - Pro:   å¹³è¡¡
  - Ultra: æ——èˆ°
2024.02  Gemini 1.5 Pro    100ä¸‡tokensä¸Šä¸‹æ–‡
2024.12  Gemini 2.0        å¤šæ¨¡æ€å¢å¼º
```

### 2.2 ä½¿ç”¨Gemini API

```python
import google.generativeai as genai

genai.configure(api_key="your-api-key")

# æ–‡æœ¬ç”Ÿæˆ
model = genai.GenerativeModel('gemini-pro')
response = model.generate_content("è§£é‡Šé‡å­è®¡ç®—")
print(response.text)

# å¤šè½®å¯¹è¯
chat = model.start_chat(history=[])
response = chat.send_message("ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ")
print(response.text)

response = chat.send_message("å®ƒå’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ")
print(response.text)
```

### 2.3 å¤šæ¨¡æ€åŠŸèƒ½

```python
# Gemini Pro Vision
import PIL.Image

model = genai.GenerativeModel('gemini-pro-vision')

# å›¾åƒç†è§£
img = PIL.Image.open('image.jpg')
response = model.generate_content([
    "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿè¯·è¯¦ç»†æè¿°",
    img
])
print(response.text)

# è§†é¢‘åˆ†æï¼ˆGemini 1.5 Proï¼‰
import google.generativeai as genai

video_file = genai.upload_file(path="video.mp4")

model = genai.GenerativeModel('gemini-1.5-pro')
response = model.generate_content([
    "æ€»ç»“è¿™ä¸ªè§†é¢‘çš„ä¸»è¦å†…å®¹",
    video_file
])
print(response.text)
```

---

## 3. è¶…é•¿ä¸Šä¸‹æ–‡åº”ç”¨

### 3.1 é•¿æ–‡æ¡£é—®ç­”

```python
# Claude 200Kä¸Šä¸‹æ–‡
with open('long_book.txt', 'r') as f:
    book_content = f.read()  # å¯ä»¥æ˜¯æ•´æœ¬ä¹¦ï¼

message = client.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=2000,
    messages=[
        {
            "role": "user",
            "content": f"åŸºäºä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n{book_content}\n\né—®é¢˜ï¼šä¸»äººå…¬çš„æ€§æ ¼ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
        }
    ]
)
```

### 3.2 ä»£ç åº“åˆ†æ

```python
# Gemini 1.5 Pro 100ä¸‡tokens
import os

def read_codebase(directory):
    code = ""
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.py'):
                with open(os.path.join(root, file)) as f:
                    code += f"# {file}\n{f.read()}\n\n"
    return code

codebase = read_codebase('./my_project')  # æ•´ä¸ªä»£ç åº“ï¼

model = genai.GenerativeModel('gemini-1.5-pro')
response = model.generate_content([
    f"åˆ†æè¿™ä¸ªä»£ç åº“çš„æ¶æ„å’Œä¸»è¦åŠŸèƒ½ï¼š\n\n{codebase}"
])
print(response.text)
```

---

## 4. æ¨¡å‹å¯¹æ¯”

| ç‰¹æ€§ | GPT-4 | Claude 3 Opus | Gemini 1.5 Pro |
|------|-------|---------------|----------------|
| ä¸Šä¸‹æ–‡ | 128K | 200K | 1000K |
| å¤šæ¨¡æ€ | âœ… | âœ… | âœ… |
| ä»£ç èƒ½åŠ› | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| æ¨ç†èƒ½åŠ› | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| ä»·æ ¼ | é«˜ | ä¸­ | ä½ |

---

## å‚è€ƒèµ„æº

- Anthropic Claudeæ–‡æ¡£
- Google AI Studio
- Gemini APIæ–‡æ¡£

