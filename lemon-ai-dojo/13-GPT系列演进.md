# GPTç³»åˆ—æ¼”è¿›

## ğŸ’¡ æ ¸å¿ƒç»“è®º

1. **GPTæ˜¯ç”Ÿæˆå¼é¢„è®­ç»ƒæ¨¡å‹ï¼Œé‡‡ç”¨å•å‘Transformer**
2. **GPT-2å±•ç¤ºäº†å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„zero-shotèƒ½åŠ›**
3. **GPT-3é€šè¿‡1750äº¿å‚æ•°å®ç°å°‘æ ·æœ¬å­¦ä¹ **
4. **InstructGPTé€šè¿‡äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ å¯¹é½äººç±»æ„å›¾**
5. **ChatGPTé€šè¿‡å¯¹è¯ä¼˜åŒ–ï¼Œæˆä¸ºç°è±¡çº§åº”ç”¨**

---

## 1. GPTå‘å±•å†ç¨‹

### 1.1 æ—¶é—´çº¿

```
2018.06  GPT-1     117Må‚æ•°   é¢„è®­ç»ƒ+å¾®è°ƒ
2019.02  GPT-2     1.5Bå‚æ•°   zero-shot
2020.05  GPT-3     175Bå‚æ•°   few-shot
2022.01  InstructGPT         RLHFå¯¹é½
2022.11  ChatGPT             å¯¹è¯ä¼˜åŒ–
2023.03  GPT-4               å¤šæ¨¡æ€
```

### 1.2 æ¶æ„æ¼”è¿›

**GPT-1**ï¼š
```
12å±‚Transformer Decoder
768ç»´éšè—å±‚
12ä¸ªæ³¨æ„åŠ›å¤´
117Må‚æ•°
```

**GPT-3**ï¼š
```
96å±‚Transformer Decoder
12288ç»´éšè—å±‚
96ä¸ªæ³¨æ„åŠ›å¤´
175Bå‚æ•°
```

---

## 2. GPTä½¿ç”¨

### 2.1 OpenAI API

```python
import openai

openai.api_key = 'your-api-key'

# GPT-3.5 Turbo
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"}
    ],
    temperature=0.7,
    max_tokens=500
)

print(response.choices[0].message.content)

# æµå¼è¾“å‡º
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "è®²ä¸ªç¬‘è¯"}],
    stream=True
)

for chunk in response:
    if 'content' in chunk.choices[0].delta:
        print(chunk.choices[0].delta.content, end='')
```

### 2.2 Prompt Engineering

```python
# Few-shotæç¤º
prompt = """
å°†ä»¥ä¸‹è¯„è®ºåˆ†ç±»ä¸ºæ­£é¢æˆ–è´Ÿé¢ï¼š

è¯„è®ºï¼šè¿™ä¸ªäº§å“å¾ˆå¥½ç”¨
åˆ†ç±»ï¼šæ­£é¢

è¯„è®ºï¼šè´¨é‡å¤ªå·®äº†
åˆ†ç±»ï¼šè´Ÿé¢

è¯„è®ºï¼šè¿˜ä¸é”™ï¼Œå€¼å¾—è´­ä¹°
åˆ†ç±»ï¼šæ­£é¢

è¯„è®ºï¼šä¸æ¨èï¼Œæµªè´¹é’±
åˆ†ç±»ï¼šè´Ÿé¢

è¯„è®ºï¼šç‰©è¶…æ‰€å€¼ï¼Œéå¸¸æ»¡æ„
åˆ†ç±»ï¼š
"""

response = openai.Completion.create(
    model="text-davinci-003",
    prompt=prompt,
    max_tokens=10
)
```

---

## 3. GPTå¾®è°ƒ

```python
# å‡†å¤‡è®­ç»ƒæ•°æ®
training_data = [
    {"prompt": "å°†è¿™å¥è¯ç¿»è¯‘æˆè‹±æ–‡ï¼šæˆ‘çˆ±å­¦ä¹ ", "completion": "I love learning"},
    {"prompt": "å°†è¿™å¥è¯ç¿»è¯‘æˆè‹±æ–‡ï¼šä»Šå¤©å¤©æ°”å¾ˆå¥½", "completion": "The weather is nice today"},
    # ... æ›´å¤šæ•°æ®
]

# å¾®è°ƒï¼ˆéœ€è¦OpenAI APIï¼‰
import openai

# ä¸Šä¼ è®­ç»ƒæ–‡ä»¶
with open('training_data.jsonl', 'w') as f:
    for item in training_data:
        f.write(json.dumps(item) + '\n')

# åˆ›å»ºå¾®è°ƒä»»åŠ¡
openai.File.create(file=open('training_data.jsonl'), purpose='fine-tune')
openai.FineTune.create(training_file='file-xxx', model='davinci')
```

---

## å‚è€ƒèµ„æº

- OpenAI APIæ–‡æ¡£
- GPT-3è®ºæ–‡
- Prompt Engineering Guide

