# å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰

## ğŸ’¡ æ ¸å¿ƒç»“è®º

1. **RNNé€šè¿‡éšè—çŠ¶æ€å¤„ç†åºåˆ—æ•°æ®**
2. **LSTMé€šè¿‡é—¨æ§æœºåˆ¶è§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜**
3. **GRUæ˜¯LSTMçš„ç®€åŒ–ç‰ˆæœ¬ï¼Œå‚æ•°æ›´å°‘**
4. **åŒå‘RNNå¯ä»¥åŒæ—¶åˆ©ç”¨å‰åæ–‡ä¿¡æ¯**
5. **Seq2Seqæ¶æ„æ˜¯æœºå™¨ç¿»è¯‘çš„åŸºç¡€**

---

## 1. RNNåŸºç¡€

### 1.1 åŸç†

```
h_t = tanh(W_hh * h_{t-1} + W_xh * x_t + b_h)
y_t = W_hy * h_t + b_y

h_t: éšè—çŠ¶æ€
x_t: å½“å‰è¾“å…¥
y_t: å½“å‰è¾“å‡º
```

### 1.2 PyTorchå®ç°

```python
import torch
import torch.nn as nn

class SimpleRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleRNN, self).__init__()
        self.hidden_size = hidden_size
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        # x: [batch_size, seq_len, input_size]
        h0 = torch.zeros(1, x.size(0), self.hidden_size)
        out, hn = self.rnn(x, h0)
        # out: [batch_size, seq_len, hidden_size]
        out = self.fc(out[:, -1, :])  # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        return out
```

---

## 2. LSTM

### 2.1 ç»“æ„

```
é—å¿˜é—¨ï¼šf_t = Ïƒ(W_f Â· [h_{t-1}, x_t] + b_f)
è¾“å…¥é—¨ï¼ši_t = Ïƒ(W_i Â· [h_{t-1}, x_t] + b_i)
è¾“å‡ºé—¨ï¼šo_t = Ïƒ(W_o Â· [h_{t-1}, x_t] + b_o)

å€™é€‰å€¼ï¼šCÌƒ_t = tanh(W_C Â· [h_{t-1}, x_t] + b_C)
ç»†èƒçŠ¶æ€ï¼šC_t = f_t âŠ™ C_{t-1} + i_t âŠ™ CÌƒ_t
éšè—çŠ¶æ€ï¼šh_t = o_t âŠ™ tanh(C_t)
```

### 2.2 å®ç°

```python
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(
            input_size, 
            hidden_size, 
            num_layers, 
            batch_first=True,
            dropout=0.2
        )
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        out, (hn, cn) = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out

# æ–‡æœ¬åˆ†ç±»ç¤ºä¾‹
model = LSTMModel(input_size=100, hidden_size=128, num_layers=2, output_size=2)
```

---

## 3. åºåˆ—é¢„æµ‹

```python
# è‚¡ç¥¨ä»·æ ¼é¢„æµ‹
import numpy as np

# å‡†å¤‡åºåˆ—æ•°æ®
def create_sequences(data, seq_length=10):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

# è®­ç»ƒ
X_train, y_train = create_sequences(train_data, seq_length=10)
X_train = torch.FloatTensor(X_train).unsqueeze(-1)
y_train = torch.FloatTensor(y_train)

model = LSTMModel(input_size=1, hidden_size=64, num_layers=2, output_size=1)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(100):
    output = model(X_train)
    loss = criterion(output.squeeze(), y_train)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

---

## å‚è€ƒèµ„æº

- ã€ŠDeep Learningã€‹- Goodfellow
- PyTorch RNN Tutorial

