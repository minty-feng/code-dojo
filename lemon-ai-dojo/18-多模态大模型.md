# 多模态大模型

## 💡 核心结论

1. **多模态模型可以理解图像、文本、音频等多种输入**
2. **CLIP通过对比学习连接图像和文本**
3. **GPT-4V支持图像输入，可以看图说话**
4. **Stable Diffusion通过文本生成图像**
5. **多模态是AI发展的重要方向**

---

## 1. CLIP

### 1.1 原理

```
图像编码器 → 图像向量
文本编码器 → 文本向量

对比学习：
- 匹配的图文对：相似度高
- 不匹配的图文对：相似度低
```

### 1.2 使用CLIP

```python
import torch
import clip
from PIL import Image

# 加载模型
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# 加载图像
image = preprocess(Image.open("cat.jpg")).unsqueeze(0).to(device)

# 文本
text = clip.tokenize(["a cat", "a dog", "a bird"]).to(device)

# 预测
with torch.no_grad():
    image_features = model.encode_image(image)
    text_features = model.encode_text(text)
    
    # 计算相似度
    logits_per_image = image_features @ text_features.T
    probs = logits_per_image.softmax(dim=-1)

print("概率:", probs.cpu().numpy())
```

---

## 2. GPT-4 Vision

```python
import openai

# 图像理解
response = openai.ChatCompletion.create(
    model="gpt-4-vision-preview",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "这张图片里有什么？"},
                {
                    "type": "image_url",
                    "image_url": "https://example.com/image.jpg"
                }
            ]
        }
    ],
    max_tokens=300
)

print(response.choices[0].message.content)
```

---

## 3. Stable Diffusion

### 3.1 文生图

```python
from diffusers import StableDiffusionPipeline
import torch

# 加载模型
model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# 生成图像
prompt = "a beautiful sunset over mountains, digital art"
negative_prompt = "ugly, blurry, low quality"

image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=50,
    guidance_scale=7.5
).images[0]

image.save("output.png")
```

### 3.2 图生图

```python
from diffusers import StableDiffusionImg2ImgPipeline
from PIL import Image

pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# 加载初始图像
init_image = Image.open("input.jpg").convert("RGB")
init_image = init_image.resize((512, 512))

prompt = "a oil painting of a cat"

images = pipe(
    prompt=prompt,
    image=init_image,
    strength=0.75,
    guidance_scale=7.5
).images

images[0].save("output.png")
```

---

## 参考资源

- CLIP论文
- Stable Diffusion文档
- GPT-4 Vision文档

