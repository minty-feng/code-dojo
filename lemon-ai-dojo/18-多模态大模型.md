# å¤šæ¨¡æ€å¤§æ¨¡å‹

## ğŸ’¡ æ ¸å¿ƒç»“è®º

1. **å¤šæ¨¡æ€æ¨¡å‹å¯ä»¥ç†è§£å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ç­‰å¤šç§è¾“å…¥**
2. **CLIPé€šè¿‡å¯¹æ¯”å­¦ä¹ è¿æ¥å›¾åƒå’Œæ–‡æœ¬**
3. **GPT-4Væ”¯æŒå›¾åƒè¾“å…¥ï¼Œå¯ä»¥çœ‹å›¾è¯´è¯**
4. **Stable Diffusioné€šè¿‡æ–‡æœ¬ç”Ÿæˆå›¾åƒ**
5. **å¤šæ¨¡æ€æ˜¯AIå‘å±•çš„é‡è¦æ–¹å‘**

---

## 1. CLIP

### 1.1 åŸç†

```
å›¾åƒç¼–ç å™¨ â†’ å›¾åƒå‘é‡
æ–‡æœ¬ç¼–ç å™¨ â†’ æ–‡æœ¬å‘é‡

å¯¹æ¯”å­¦ä¹ ï¼š
- åŒ¹é…çš„å›¾æ–‡å¯¹ï¼šç›¸ä¼¼åº¦é«˜
- ä¸åŒ¹é…çš„å›¾æ–‡å¯¹ï¼šç›¸ä¼¼åº¦ä½
```

### 1.2 ä½¿ç”¨CLIP

```python
import torch
import clip
from PIL import Image

# åŠ è½½æ¨¡å‹
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# åŠ è½½å›¾åƒ
image = preprocess(Image.open("cat.jpg")).unsqueeze(0).to(device)

# æ–‡æœ¬
text = clip.tokenize(["a cat", "a dog", "a bird"]).to(device)

# é¢„æµ‹
with torch.no_grad():
    image_features = model.encode_image(image)
    text_features = model.encode_text(text)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    logits_per_image = image_features @ text_features.T
    probs = logits_per_image.softmax(dim=-1)

print("æ¦‚ç‡:", probs.cpu().numpy())
```

---

## 2. GPT-4 Vision

```python
import openai

# å›¾åƒç†è§£
response = openai.ChatCompletion.create(
    model="gpt-4-vision-preview",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"},
                {
                    "type": "image_url",
                    "image_url": "https://example.com/image.jpg"
                }
            ]
        }
    ],
    max_tokens=300
)

print(response.choices[0].message.content)
```

---

## 3. Stable Diffusion

### 3.1 æ–‡ç”Ÿå›¾

```python
from diffusers import StableDiffusionPipeline
import torch

# åŠ è½½æ¨¡å‹
model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# ç”Ÿæˆå›¾åƒ
prompt = "a beautiful sunset over mountains, digital art"
negative_prompt = "ugly, blurry, low quality"

image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=50,
    guidance_scale=7.5
).images[0]

image.save("output.png")
```

### 3.2 å›¾ç”Ÿå›¾

```python
from diffusers import StableDiffusionImg2ImgPipeline
from PIL import Image

pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# åŠ è½½åˆå§‹å›¾åƒ
init_image = Image.open("input.jpg").convert("RGB")
init_image = init_image.resize((512, 512))

prompt = "a oil painting of a cat"

images = pipe(
    prompt=prompt,
    image=init_image,
    strength=0.75,
    guidance_scale=7.5
).images

images[0].save("output.png")
```

---

## å‚è€ƒèµ„æº

- CLIPè®ºæ–‡
- Stable Diffusionæ–‡æ¡£
- GPT-4 Visionæ–‡æ¡£

