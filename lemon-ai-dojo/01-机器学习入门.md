# 机器学习入门

## 💡 核心结论

1. **机器学习是让计算机从数据中学习规律，而非显式编程**
2. **监督学习、无监督学习、强化学习是三大学习范式**
3. **训练集、验证集、测试集的划分是防止过拟合的关键**
4. **特征工程往往比模型选择更重要**
5. **没有免费的午餐：没有一个算法适用于所有问题**

---

## 1. 什么是机器学习

### 1.1 定义

**机器学习（Machine Learning）**：让计算机通过经验自动改进的算法

```
传统编程：规则 + 数据 → 输出
机器学习：数据 + 输出 → 规则
```

**示例**：
- **传统编程**：写规则判断邮件是否为垃圾邮件
- **机器学习**：从标注好的邮件数据中学习判断规则

### 1.2 机器学习 vs 深度学习 vs AI

```
人工智能 (AI)
    ├── 机器学习 (ML)
    │   ├── 监督学习
    │   ├── 无监督学习
    │   ├── 强化学习
    │   └── 深度学习 (DL)
    │       ├── CNN
    │       ├── RNN
    │       ├── Transformer
    │       └── ...
    └── 其他AI技术
        ├── 专家系统
        ├── 知识图谱
        └── ...
```

---

## 2. 三大学习范式

### 2.1 监督学习（Supervised Learning）

**定义**：从标注数据中学习输入到输出的映射

**应用场景**：
- **分类**：垃圾邮件识别、图像分类、情感分析
- **回归**：房价预测、股票预测、销量预测

**示例**：
```python
# 训练数据（已标注）
X_train = [[2, 3], [3, 4], [4, 5]]  # 特征
y_train = [0, 1, 1]                  # 标签

# 训练模型
model.fit(X_train, y_train)

# 预测新数据
X_test = [[5, 6]]
y_pred = model.predict(X_test)  # 预测标签
```

### 2.2 无监督学习（Unsupervised Learning）

**定义**：从无标注数据中发现隐藏模式

**应用场景**：
- **聚类**：用户分群、异常检测
- **降维**：数据可视化、特征提取
- **关联规则**：购物篮分析

**示例**：
```python
# 训练数据（无标注）
X = [[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6]]

# K-means聚类
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=2)
labels = kmeans.fit_predict(X)  # [0, 0, 1, 1, 0]
```

### 2.3 强化学习（Reinforcement Learning）

**定义**：通过与环境交互，学习最优决策策略

**应用场景**：
- 游戏AI（AlphaGo）
- 机器人控制
- 自动驾驶

**核心概念**：
```
Agent（智能体）
    ↓ Action（动作）
Environment（环境）
    ↓ Reward（奖励）
Agent学习最大化累积奖励
```

---

## 3. 机器学习工作流程

### 3.1 标准流程

```
1. 问题定义 → 确定目标和评估指标
2. 数据收集 → 获取相关数据
3. 数据探索 → 理解数据分布和特征
4. 数据预处理 → 清洗、转换、归一化
5. 特征工程 → 特征选择、特征构造
6. 模型选择 → 选择合适的算法
7. 模型训练 → 在训练集上训练
8. 模型评估 → 在验证集上评估
9. 模型调优 → 超参数优化
10. 模型测试 → 在测试集上最终评估
11. 模型部署 → 上线应用
12. 监控维护 → 持续监控和更新
```

### 3.2 数据划分

```python
from sklearn.model_selection import train_test_split

# 划分训练集和测试集（80% / 20%）
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 从训练集中划分验证集
X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42
)

# 最终：训练集64%、验证集16%、测试集20%
```

**作用**：
- **训练集**：训练模型参数
- **验证集**：调整超参数，选择模型
- **测试集**：最终评估模型性能

---

## 4. 核心概念

### 4.1 过拟合与欠拟合

```
欠拟合（Underfitting）
- 模型太简单
- 训练误差高，测试误差高
- 解决：增加模型复杂度、添加特征

过拟合（Overfitting）
- 模型太复杂，记住了训练数据的噪声
- 训练误差低，测试误差高
- 解决：正则化、增加数据、减少特征
```

**示例**：
```python
import numpy as np
import matplotlib.pyplot as plt

# 生成数据
X = np.linspace(0, 10, 100).reshape(-1, 1)
y = 2 * X + 1 + np.random.randn(100, 1) * 2

# 欠拟合：线性模型拟合非线性数据
# 适当拟合：线性模型拟合线性数据
# 过拟合：高次多项式模型

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# 过拟合例子：20次多项式
poly = PolynomialFeatures(degree=20)
X_poly = poly.fit_transform(X)
model = LinearRegression()
model.fit(X_poly, y)
```

### 4.2 偏差-方差权衡

```
总误差 = 偏差² + 方差 + 噪声

偏差（Bias）：
- 模型的预测值与真实值的偏离程度
- 高偏差 → 欠拟合

方差（Variance）：
- 模型在不同训练集上预测的变化程度
- 高方差 → 过拟合
```

### 4.3 正则化

**L1正则化（Lasso）**：
```python
from sklearn.linear_model import Lasso

# L1: 最小化 (损失函数 + λ * |权重|)
model = Lasso(alpha=0.1)  # alpha是λ
model.fit(X_train, y_train)

# 特点：可以将某些权重变为0（特征选择）
```

**L2正则化（Ridge）**：
```python
from sklearn.linear_model import Ridge

# L2: 最小化 (损失函数 + λ * 权重²)
model = Ridge(alpha=0.1)
model.fit(X_train, y_train)

# 特点：权重趋近于0但不为0
```

---

## 5. 常用评估指标

### 5.1 分类问题

**混淆矩阵**：
```
                预测
                正例    负例
实际  正例      TP      FN
     负例      FP      TN

TP: True Positive（真正例）
FP: False Positive（假正例）
TN: True Negative（真负例）
FN: False Negative（假负例）
```

**评估指标**：
```python
# 准确率（Accuracy）
accuracy = (TP + TN) / (TP + TN + FP + FN)

# 精确率（Precision）：预测为正的样本中，实际为正的比例
precision = TP / (TP + FP)

# 召回率（Recall）：实际为正的样本中，被预测为正的比例
recall = TP / (TP + FN)

# F1分数：精确率和召回率的调和平均
F1 = 2 * (precision * recall) / (precision + recall)
```

**使用scikit-learn**：
```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

y_true = [1, 0, 1, 1, 0, 1]
y_pred = [1, 0, 1, 0, 0, 1]

print(f"Accuracy: {accuracy_score(y_true, y_pred)}")
print(f"Precision: {precision_score(y_true, y_pred)}")
print(f"Recall: {recall_score(y_true, y_pred)}")
print(f"F1: {f1_score(y_true, y_pred)}")
```

### 5.2 回归问题

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# 均方误差（MSE）
mse = mean_squared_error(y_true, y_pred)

# 均方根误差（RMSE）
rmse = np.sqrt(mse)

# 平均绝对误差（MAE）
mae = mean_absolute_error(y_true, y_pred)

# R²分数（决定系数）
r2 = r2_score(y_true, y_pred)  # 越接近1越好
```

---

## 6. 第一个机器学习项目

### 6.1 房价预测（回归）

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# 1. 加载数据
# 假设有房屋面积、房间数、建造年份等特征
data = pd.DataFrame({
    'area': [50, 60, 70, 80, 90, 100, 110, 120],
    'rooms': [1, 2, 2, 3, 3, 3, 4, 4],
    'age': [10, 8, 5, 3, 2, 1, 0, 0],
    'price': [200, 250, 300, 350, 400, 450, 500, 550]  # 单位：万
})

# 2. 数据探索
print(data.describe())
print(data.corr())

# 3. 准备数据
X = data[['area', 'rooms', 'age']]
y = data['price']

# 4. 划分数据集
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 5. 训练模型
model = LinearRegression()
model.fit(X_train, y_train)

# 6. 预测
y_pred = model.predict(X_test)

# 7. 评估
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.2f}")
print(f"R²: {r2:.2f}")
print(f"权重: {model.coef_}")
print(f"截距: {model.intercept_:.2f}")

# 8. 可视化
plt.scatter(y_test, y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('真实价格')
plt.ylabel('预测价格')
plt.title('房价预测')
plt.show()

# 9. 预测新数据
new_house = [[85, 3, 5]]  # 85平米，3室，5年房龄
predicted_price = model.predict(new_house)
print(f"预测价格: {predicted_price[0]:.2f}万")
```

### 6.2 鸢尾花分类（分类）

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import seaborn as sns

# 1. 加载经典数据集
iris = load_iris()
X = iris.data
y = iris.target

# 2. 划分数据
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 3. 训练决策树模型
model = DecisionTreeClassifier(max_depth=3, random_state=42)
model.fit(X_train, y_train)

# 4. 预测
y_pred = model.predict(X_test)

# 5. 评估
accuracy = accuracy_score(y_test, y_pred)
print(f"准确率: {accuracy:.2%}")
print("\n分类报告:")
print(classification_report(y_test, y_pred, target_names=iris.target_names))

# 6. 混淆矩阵可视化
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('预测')
plt.ylabel('实际')
plt.title('混淆矩阵')
plt.show()
```

---

## 7. 机器学习常用库

### 7.1 核心库

```python
# NumPy：数值计算
import numpy as np
arr = np.array([1, 2, 3, 4, 5])

# Pandas：数据处理
import pandas as pd
df = pd.read_csv('data.csv')

# Matplotlib：数据可视化
import matplotlib.pyplot as plt
plt.plot([1, 2, 3], [4, 5, 6])

# Scikit-learn：机器学习
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
```

### 7.2 安装环境

```bash
# 创建虚拟环境
conda create -n ml python=3.9
conda activate ml

# 安装核心库
pip install numpy pandas matplotlib seaborn
pip install scikit-learn

# 安装Jupyter
pip install jupyter
jupyter notebook
```

---

## 8. 学习路径

### 8.1 基础知识

1. **数学基础**：
   - 线性代数：矩阵运算、特征值
   - 微积分：导数、梯度
   - 概率统计：概率分布、贝叶斯定理

2. **编程基础**：
   - Python语法
   - NumPy、Pandas
   - 数据可视化

### 8.2 进阶路线

```
机器学习基础
    ↓
监督学习算法
    ↓
无监督学习算法
    ↓
模型评估与调优
    ↓
实战项目
    ↓
深度学习
```

---

## 9. 常见问题

### Q1: 机器学习需要多少数学？
**A**: 
- 入门：基础线性代数和概率
- 进阶：微积分、统计学
- 研究：高等数学、优化理论

### Q2: 如何选择算法？
**A**:
1. 数据量大小
2. 特征维度
3. 问题类型（分类/回归）
4. 可解释性要求
5. 性能要求

### Q3: 过拟合如何解决？
**A**:
1. 增加训练数据
2. 正则化
3. 交叉验证
4. 简化模型
5. 早停（Early Stopping）

---

## 10. 实践建议

1. **动手实践**：理论结合代码
2. **参加竞赛**：Kaggle、天池
3. **阅读论文**：了解前沿技术
4. **做项目**：完整的端到端项目
5. **持续学习**：AI发展迅速

---

## 参考资源

- 《机器学习实战》- Peter Harrington
- 《统计学习方法》- 李航
- Coursera: Machine Learning - Andrew Ng
- Kaggle Learn
- Scikit-learn官方文档

