# AIä¼¦ç†ä¸å®‰å…¨

## ğŸ’¡ æ ¸å¿ƒç»“è®º

1. **AIæ¨¡å‹å¯èƒ½å­˜åœ¨åè§ï¼Œéœ€è¦å…¬å¹³æ€§è¯„ä¼°**
2. **å¯¹æŠ—æ ·æœ¬å¯ä»¥æ¬ºéª—æ¨¡å‹ï¼Œéœ€è¦é²æ£’æ€§æµ‹è¯•**
3. **éšç§ä¿æŠ¤é€šè¿‡å·®åˆ†éšç§ã€è”é‚¦å­¦ä¹ ç­‰æŠ€æœ¯**
4. **AIç”Ÿæˆå†…å®¹éœ€è¦æ°´å°å’Œæ£€æµ‹æœºåˆ¶**
5. **è´Ÿè´£ä»»çš„AIå¼€å‘éœ€è¦é€æ˜æ€§å’Œå¯è§£é‡Šæ€§**

---

## 1. AIåè§

### 1.1 å¸¸è§åè§ç±»å‹

```
æ•°æ®åè§ï¼š
- å†å²åè§ï¼šè®­ç»ƒæ•°æ®åæ˜ å†å²æ­§è§†
- é‡‡æ ·åè§ï¼šæ•°æ®ä¸å…·ä»£è¡¨æ€§

ç®—æ³•åè§ï¼š
- ç‰¹å¾é€‰æ‹©åè§
- è¯„ä¼°æŒ‡æ ‡åè§
```

### 1.2 æ£€æµ‹åè§

```python
# æ£€æŸ¥æ€§åˆ«åè§
from aif360.datasets import BinaryLabelDataset
from aif360.metrics import BinaryLabelDatasetMetric

# è®¡ç®—ä¸åŒç¾¤ä½“çš„ç»“æœå·®å¼‚
metric = BinaryLabelDatasetMetric(dataset, 
    unprivileged_groups=[{'gender': 0}],
    privileged_groups=[{'gender': 1}]
)

print(f"å·®å¼‚å½±å“: {metric.disparate_impact()}")
```

---

## 2. å¯¹æŠ—æ”»å‡»

### 2.1 FGSMæ”»å‡»

```python
def fgsm_attack(image, epsilon, data_grad):
    # è·å–æ¢¯åº¦ç¬¦å·
    sign_data_grad = data_grad.sign()
    # æ·»åŠ æ‰°åŠ¨
    perturbed_image = image + epsilon * sign_data_grad
    # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
    perturbed_image = torch.clamp(perturbed_image, 0, 1)
    return perturbed_image

# ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
image.requires_grad = True
output = model(image)
loss = criterion(output, target)
model.zero_grad()
loss.backward()

# æ·»åŠ æ‰°åŠ¨
perturbed_data = fgsm_attack(image, epsilon=0.1, data_grad=image.grad.data)

# éªŒè¯æ”»å‡»æ•ˆæœ
output_after = model(perturbed_data)
```

---

## 3. æ¨¡å‹å¯è§£é‡Šæ€§

### 3.1 SHAP

```python
import shap

# åŠ è½½æ¨¡å‹
model = xgboost.XGBClassifier()
model.fit(X_train, y_train)

# SHAPè§£é‡Šå™¨
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# å¯è§†åŒ–
shap.summary_plot(shap_values, X_test)
```

---

## å‚è€ƒèµ„æº

- AI Fairness 360
- SHAPåº“æ–‡æ¡£
- ã€ŠResponsible AIã€‹

